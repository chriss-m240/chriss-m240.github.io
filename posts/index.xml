<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Visual Computing Course - Group site</title>
    <link>/posts/</link>
    <description>Recent content in Posts on Visual Computing Course - Group site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>D3-Hugo integration task</title>
      <link>/posts/d3_hugo_integration_task/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/d3_hugo_integration_task/</guid>
      <description>Te following task is an example of how to add a D3 chart into the Hugo webpage by writting some JS code into the project. The JS code to this specific visualization can be found in the /static/js/chart.js file, where there are some variables and data declared for D3 to properly work and render.
In the case of the .md files there is only a few lines of HTML, defining the use of D3 via a CDN and referencing the JS script mecioned before.</description>
    </item>
    
    <item>
      <title>Lab 1, task 1. P5 - Grayscale RGB &amp; Luma</title>
      <link>/posts/p5_gray_scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/p5_gray_scale/</guid>
      <description>The first image is the original colorfull image which we are going to transform into black and white images with the following tehcniques. Arithmetic mean This metod is just the i.e. average, of the three components, in the HSI model called intensity (fig. a). This is simply the projection of a point onto the neutral axis—the vertical height of a point in our tilted cube. The advantage is that, together with Euclidean-distance calculations of hue and chroma, this representation preserves distances and angles from the geometry of the RGB cube.</description>
    </item>
    
    <item>
      <title>Lab 1, task 2. P5 - Convolution masks</title>
      <link>/posts/p5_convolution_example/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/p5_convolution_example/</guid>
      <description>Let&#39;s start understanding a little bit about convolutional masks, also known as kernels. It&#39;s a concept normally used in visual computing because it refers to a matrix where some values are defined to achieve certain effect over images or videos. The most common convolutional mask is the blur kernel used to soften an image and create a foggy or a fade effect, here it is what is know as a box blur kernel, characteristic because it defines that the color for a pixel is the arithmetic mean of its neighboring pixels.</description>
    </item>
    
    <item>
      <title>Lab 1, task 3. P5 - Image Histogram and Segmentation</title>
      <link>/posts/p5_histogram_segmentation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/p5_histogram_segmentation/</guid>
      <description>Image Histograms Image histograms visually summarize the distribution of a continuous numeric variable by measuring the frequency at which certain values appear in the image. The x-axis in the image histogram is a number line that displays the range of image pixel values that has been split into number ranges, or bins. A bar is drawn for each bin, and the width of the bar represents the density number range of the bin; the height of the bar represents the number of pixels that fall into that range.</description>
    </item>
    
    <item>
      <title>Lab 1, task 4. P5 - Video analysis</title>
      <link>/posts/p5_video_analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/p5_video_analysis/</guid>
      <description>At first we tried to run the convolutional masks on a video at software level, unfortunaly there was no possible to execute it because the resources given by the browser to the page were not enough to support the complete processing of the video, returning as and error the following.
With that is notorius that running convolutional mask on a software level is no efficient and it takes several computational resources to compute it.</description>
    </item>
    
    <item>
      <title>Lab 2, Optical Illusions</title>
      <link>/posts/p5_optical_illusion_example/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/p5_optical_illusion_example/</guid>
      <description>--            Illusion Category Reference Type of interactivity(if applies) Base code URL(if applies)     Cafe wall Geometric https://en.wikipedia.org/wiki/Caf%C3%A9_wall_illusion Mouse movement X axis https://github.com/visual-comp/visual-comp.github.io/blob/master/js/illusions/cafeWall.js   Mobius strip Paradox https://www.illusionsindex.org/i/ambiguous-ring None https://github.com/visual-comp/visual-comp.github.io/blob/master/js/illusions/mobiusStrip.js   Penrose triangle Paradox https://en.wikipedia.org/wiki/Penrose_triangle Mouse click, Mouse movement X, Y axis https://github.com/visual-comp/visual-comp.github.io/blob/master/js/illusions/penroseTriangle.js   Muller lyer Size distorsion https://en.wikipedia.org/wiki/M%C3%BCller-Lyer_illusion None https://github.com/visual-comp/visual-comp.github.io/blob/master/js/illusions/mullerLyer.js   Ebbinghaus illusion Size distorsion https://en.</description>
    </item>
    
    <item>
      <title>Lab 3, Illumination scenes</title>
      <link>/posts/p5_illumination/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/p5_illumination/</guid>
      <description>Ambient light Ambient light is “background” light. It bounces everywhere in all directions and comes from no specific place. Ambient light illuminates every face of a model regardless of the face’s orientation to a light source. All faces get the same amount of ambient light.
Ambient light is modeled as a three component vector, where each value represents a percentage of color that is visible.</description>
    </item>
    
    <item>
      <title>NeRF - Neural Radiance Fields</title>
      <link>/posts/project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/project/</guid>
      <description>Ray tracing In 3D computer graphics, ray tracing is a rendering technique for generating an image by tracing the path of light as pixels in an image plane and simulating the effects of its encounters with virtual objects. The technique is capable of producing a high degree of visual realism, more so than typical scanline rendering methods, but at a greater computational cost. This makes ray tracing best suited for applications where taking a relatively long time to render can be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but more poorly suited to real-time applications such as video games, where speed is critical in rendering each frame.</description>
    </item>
    
  </channel>
</rss>
